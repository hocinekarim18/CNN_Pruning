{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df4976fd",
   "metadata": {},
   "source": [
    "## Bibilioth√®que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da05cba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf;\n",
    "import matplotlib.pyplot as plt\n",
    "from resnet import resnet_v2\n",
    "import time\n",
    "%matplotlib inline\n",
    "seed = tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c602222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(figname):\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(accuracy, label = \"train accuracy\")\n",
    "    plt.plot(val_accuracy, label = \"validation accuracy\")\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(l, label = \"train loss\")\n",
    "    plt.plot(val_l, label = \"validation loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(figname)\n",
    "    plt.show()\n",
    "    \n",
    "def inference_time():\n",
    "    scratch = []\n",
    "    pruned = []\n",
    "    for i in range(10):\n",
    "        t1 = time.time()\n",
    "        pred1 = scratch_model(x_test)\n",
    "        t2 = time.time()\n",
    "        scratch.append(t2-t1)\n",
    "\n",
    "        # Pruned model\n",
    "        t3 = time.time()\n",
    "        pred2 = P.model(x_test)\n",
    "        t4 = time.time()\n",
    "        pruned.append(t4-t3)\n",
    "\n",
    "    # display\n",
    "    print(\"Scratch inference time : \", np.mean(scratch), \" s\")\n",
    "    print(\"Pruned inference time : \", np.mean(pruned), \" s\")\n",
    "    return np.mean(pruned)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    somme = 0\n",
    "    for l in model.trainable_variables:\n",
    "        somme += np.count_nonzero(l)\n",
    "    return somme\n",
    "\n",
    "\n",
    "\n",
    "def scratch_hist():   \n",
    "    loss = dico[\"scratch_hist\"][0].history[\"loss\"]\n",
    "    val_loss = dico[\"scratch_hist\"][0].history[\"val_loss\"]\n",
    "    accuracy = dico[\"scratch_hist\"][0].history[\"sparse_categorical_accuracy\"]\n",
    "    val_accuracy =  dico[\"scratch_hist\"][0].history[\"val_sparse_categorical_accuracy\"]\n",
    "\n",
    "    for i in range(len( dico[\"scratch_hist\"])):\n",
    "        if i !=0:\n",
    "            loss = np.append(loss, dico[\"scratch_hist\"][i].history[\"loss\"])\n",
    "            val_loss = np.append(val_loss, dico[\"scratch_hist\"][i].history[\"val_loss\"])\n",
    "            accuracy = np.append(accuracy, dico[\"scratch_hist\"][i].history[\"sparse_categorical_accuracy\"])\n",
    "            val_accuracy =  np.append(val_accuracy, dico[\"scratch_hist\"][i].history[\"val_sparse_categorical_accuracy\"])\n",
    "\n",
    "    dico[\"scratch_hist\"] = (accuracy, val_accuracy, loss, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8cf7b",
   "metadata": {},
   "source": [
    "## Loading Mnist Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2339918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Data Loading ================\n",
      "x_train shape: (60000, 28, 28)\n",
      "x_test shape: (10000, 28, 28)\n",
      "y_train shape: (60000,)\n",
      "y_test shape: (10000,)\n",
      "\n",
      "x_train shape: (60000, 32, 32)\n",
      "x_test shape: (10000, 32, 32)\n",
      "y_train shape: (60000,)\n",
      "y_test shape: (10000,)\n",
      "\n",
      "x_train shape: (60000, 32, 32, 1)\n",
      "x_test shape: (10000, 32, 32, 1)\n",
      "y_train shape: (60000,)\n",
      "y_test shape: (10000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def padding_mnist(x_train, x_test, pad=1):\n",
    "    \n",
    "    x = np.zeros((x_train.shape[0],x_train.shape[1]+2*pad, x_train.shape[2]+2*pad ))\n",
    "    xt = np.zeros((x_test.shape[0],x_test.shape[1]+2*pad, x_test.shape[2]+2*pad ))\n",
    "    \n",
    "    for i in range(x_train.shape[0]):\n",
    "        x[i] = np.pad(x_train[i], pad)\n",
    "        if i < x_test.shape[0]:\n",
    "            xt[i] = np.pad(x_test[i], pad)\n",
    "            \n",
    "    return (x, xt)\n",
    "            \n",
    "        \n",
    "\n",
    "print(\"================ Data Loading ================\")\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Data shapes\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#padding\n",
    "x_train, x_test = padding_mnist(x_train, x_test, pad=2)\n",
    "\n",
    "# Data shapes\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"\")\n",
    "\n",
    "x_train = np.reshape(x_train, (-1,32,32,1))\n",
    "x_test = np.reshape(x_test, (-1,32,32,1))\n",
    "\n",
    "# Data shapes\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66b092",
   "metadata": {},
   "source": [
    "## Building Lenet5 model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d168fdc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               48120     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-20 11:11:56.148785: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-20 11:11:56.148809: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-20 11:11:56.148823: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (karim-Swift-SF514-53T): /proc/driver/nvidia/version does not exist\n",
      "2022-07-20 11:11:56.149385: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=6, kernel_size=(5, 5), activation='relu', input_shape=(32,32,1)),\n",
    "    tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=2, padding=\"valid\"),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), activation='relu'),\n",
    "    tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=2, padding=\"valid\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=120, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=84, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=10, activation=\"softmax\")\n",
    "\n",
    "]);\n",
    "\n",
    "model.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035728c6",
   "metadata": {},
   "source": [
    "## Scratch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b271752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disctionnaire pour enregistrer les infos pertinentes\n",
    "dico = {}\n",
    "scratch_model = tf.keras.models.clone_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dea2a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "lr = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02397941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-20 11:12:04.055347: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 245760000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2252 - sparse_categorical_accuracy: 0.9280 - val_loss: 0.0623 - val_sparse_categorical_accuracy: 0.9806\n",
      "Epoch 2/75\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0701 - sparse_categorical_accuracy: 0.9783 - val_loss: 0.0625 - val_sparse_categorical_accuracy: 0.9802\n",
      "Epoch 3/75\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0491 - sparse_categorical_accuracy: 0.9843 - val_loss: 0.0329 - val_sparse_categorical_accuracy: 0.9888\n",
      "Epoch 4/75\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0385 - sparse_categorical_accuracy: 0.9876 - val_loss: 0.0412 - val_sparse_categorical_accuracy: 0.9873\n",
      "Epoch 5/75\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0311 - sparse_categorical_accuracy: 0.9903 - val_loss: 0.0395 - val_sparse_categorical_accuracy: 0.9877\n",
      "Epoch 6/75\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0259 - sparse_categorical_accuracy: 0.9915 - val_loss: 0.0297 - val_sparse_categorical_accuracy: 0.9906\n",
      "Epoch 7/75\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0215 - sparse_categorical_accuracy: 0.9929 - val_loss: 0.0337 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 8/75\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0197 - sparse_categorical_accuracy: 0.9934 - val_loss: 0.0376 - val_sparse_categorical_accuracy: 0.9883\n",
      "Epoch 9/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0154 - sparse_categorical_accuracy: 0.9952 - val_loss: 0.0445 - val_sparse_categorical_accuracy: 0.9875\n",
      "Epoch 10/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0143 - sparse_categorical_accuracy: 0.9952 - val_loss: 0.0415 - val_sparse_categorical_accuracy: 0.9885\n",
      "Epoch 11/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0126 - sparse_categorical_accuracy: 0.9956 - val_loss: 0.0433 - val_sparse_categorical_accuracy: 0.9888\n",
      "Epoch 12/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0112 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0383 - val_sparse_categorical_accuracy: 0.9895\n",
      "Epoch 13/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0410 - val_sparse_categorical_accuracy: 0.9896\n",
      "Epoch 14/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0384 - val_sparse_categorical_accuracy: 0.9899\n",
      "Epoch 15/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0368 - val_sparse_categorical_accuracy: 0.9899\n",
      "Epoch 16/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0492 - val_sparse_categorical_accuracy: 0.9878\n",
      "Epoch 17/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0459 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 18/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0435 - val_sparse_categorical_accuracy: 0.9901\n",
      "Epoch 19/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0393 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 20/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.0392 - val_sparse_categorical_accuracy: 0.9904\n",
      "Epoch 21/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.0397 - val_sparse_categorical_accuracy: 0.9916\n",
      "Epoch 22/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9991 - val_loss: 0.0508 - val_sparse_categorical_accuracy: 0.9881\n",
      "Epoch 23/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.0474 - val_sparse_categorical_accuracy: 0.9899\n",
      "Epoch 24/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0471 - val_sparse_categorical_accuracy: 0.9884\n",
      "Epoch 25/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0492 - val_sparse_categorical_accuracy: 0.9877\n",
      "Epoch 26/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.0457 - val_sparse_categorical_accuracy: 0.9904\n",
      "Epoch 27/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.0440 - val_sparse_categorical_accuracy: 0.9905\n",
      "Epoch 28/75\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9992 - val_loss: 0.0526 - val_sparse_categorical_accuracy: 0.9896\n",
      "Epoch 29/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9991 - val_loss: 0.0504 - val_sparse_categorical_accuracy: 0.9893\n",
      "Epoch 30/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.0461 - val_sparse_categorical_accuracy: 0.9905\n",
      "Epoch 31/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9900\n",
      "Epoch 32/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0030 - sparse_categorical_accuracy: 0.9991 - val_loss: 0.0460 - val_sparse_categorical_accuracy: 0.9905\n",
      "Epoch 33/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 5.5611e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.0486 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 34/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 5.1681e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.0480 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 35/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.4124e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0482 - val_sparse_categorical_accuracy: 0.9911\n",
      "Epoch 36/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 7.4842e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0489 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 37/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 5.1847e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0495 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 38/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 4.2440e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0505 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 39/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 3.8773e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0509 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 40/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 3.5939e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0514 - val_sparse_categorical_accuracy: 0.9913\n",
      "Epoch 41/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 3.2634e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0517 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 42/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 2.8952e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0521 - val_sparse_categorical_accuracy: 0.9916\n",
      "Epoch 43/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 2.6791e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0526 - val_sparse_categorical_accuracy: 0.9916\n",
      "Epoch 44/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 2.4536e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0531 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 45/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 12s 6ms/step - loss: 2.3139e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0534 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 46/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 2.1489e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0537 - val_sparse_categorical_accuracy: 0.9916\n",
      "Epoch 47/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 2.0337e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0540 - val_sparse_categorical_accuracy: 0.9916\n",
      "Epoch 48/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.8943e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0543 - val_sparse_categorical_accuracy: 0.9916\n",
      "Epoch 49/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.8388e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0544 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 50/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.7012e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0548 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 51/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.6328e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0550 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 52/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.5635e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0553 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 53/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.5098e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0556 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 54/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.4413e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0558 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 55/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.3924e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0560 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 56/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.3292e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0562 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 57/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.2748e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0564 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 58/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.2311e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0565 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 59/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.1945e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0567 - val_sparse_categorical_accuracy: 0.9913\n",
      "Epoch 60/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.1620e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0569 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 61/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.1198e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0571 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 62/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.0823e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0573 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 63/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.0520e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0574 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 64/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.0147e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0576 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 65/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 9.8331e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0578 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 66/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 9.6639e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0580 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 67/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 9.3391e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0581 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 68/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 9.1365e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0583 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 69/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 8.9040e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0584 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 70/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 8.6778e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0586 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 71/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 8.3915e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0588 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 72/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 8.3232e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0589 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 73/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 8.1118e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0589 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 74/75\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.8199e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0590 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 75/75\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 7.7705e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0592 - val_sparse_categorical_accuracy: 0.9914\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0592 - sparse_categorical_accuracy: 0.9914\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-20 11:27:36.222875: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 245760000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 13s 7ms/step - loss: 7.3838e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0592 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.3646e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0592 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.3454e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0593 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.3279e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0593 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 7.3111e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0593 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.2947e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0593 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 7.2765e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0593 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.2630e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0593 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.2474e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0593 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.2310e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0593 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 7.2177e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.2017e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.1869e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.1715e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.1580e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9915\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0594 - sparse_categorical_accuracy: 0.9915\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-20 11:30:44.520403: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 245760000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 13s 7ms/step - loss: 7.1262e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.1247e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.1232e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.1218e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9916\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.1204e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9916\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.1190e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9916\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 7.1174e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9916\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 7.1162e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9916\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 7.1148e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9916\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 7.1134e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9916\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0594 - sparse_categorical_accuracy: 0.9916\n"
     ]
    }
   ],
   "source": [
    "dico[\"scratch_hist\"] = []\n",
    "for epoch in [75, 15, 10 ]:\n",
    "    lr /= 10\n",
    "    scratch_model.compile(\n",
    "            optimizer = tf.keras.optimizers.SGD(learning_rate=lr),\n",
    "            metrics = [tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "            loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "            )\n",
    "\n",
    "        # Train and evaluate on data.\n",
    "    hist = scratch_model.fit(x_train, y_train, \n",
    "          batch_size = BATCH_SIZE,\n",
    "          epochs= epoch,\n",
    "          steps_per_epoch = len(x_train)/BATCH_SIZE,\n",
    "          validation_data =(x_test, y_test),\n",
    "          workers =40,\n",
    "          use_multiprocessing= True,\n",
    "          )\n",
    "\n",
    "    scratch_model.evaluate(x_test, y_test)\n",
    "    dico[\"scratch_hist\"].append(hist)\n",
    "scratch_hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e3c767",
   "metadata": {},
   "source": [
    "## Pruning class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "565846c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pruning:\n",
    "    def __init__(self, model, pruning_factor = 0.5):\n",
    "        \n",
    "        # attributs li√©s au model\n",
    "        self.model = model\n",
    "        self.pruning_factor = pruning_factor\n",
    "    \n",
    "    # Tensorflow utils setting\n",
    "    def compile(self,optimizer, loss_fn, metric):\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.acc_metric = metric\n",
    "    \n",
    "    # Pruning Function\n",
    "    def pruning(self, P_factor = 0.5):\n",
    "        if P_factor >=1 or P_factor <= 0:\n",
    "            raise ValueError (\"Pruning factor value Error : Pruning factor value should be ]0 ;1[\")\n",
    "        for layer in self.model.layers:\n",
    "            if \"conv\" in layer.name:\n",
    "                \n",
    "                # R√©cuper les kernels\n",
    "                w = layer.get_weights()[0]\n",
    "                b = layer.get_weights()[1]\n",
    "                \n",
    "                # Calcul du filtre contenant la median\n",
    "                tab = []\n",
    "                for i in range(w.shape[-1]):\n",
    "                    somme = 0\n",
    "                    for j in range(w.shape[-1]):\n",
    "                        if i !=j:\n",
    "                            somme += np.linalg.norm(w[:,:,:,i] - w[:,:,:,j])\n",
    "                    tab.append(somme)\n",
    "                    \n",
    "                # calcul du nombre de filtrer a annuler selon le facteur de pruning\n",
    "                nb_pruned_filters = int(w.shape[-1]*P_factor)\n",
    "                \n",
    "                for i in range(nb_pruned_filters):\n",
    "                    # r√©cup√©rer l'indice du minimum\n",
    "                    ind_min = np.argmin(tab)\n",
    "                    \n",
    "                    #anuuler le filtre qui minimise la formule pr√©cedente\n",
    "                    w[:, :, :, ind_min] = np.zeros(w[:, :, :, ind_min].shape)\n",
    "                    \n",
    "                    # astuce pour d√©placer le minimum lorsque il faut annuler plusieurs filtres\n",
    "                    tab[ind_min] = 1e10\n",
    "                \n",
    "                layer.set_weights([w, b])\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "    #Training algorithm\n",
    "    def train(self,x_train, y_train, val_data, val_labels, epochs = 100, batch_size= 32):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # training history storage\n",
    "        accur = []\n",
    "        L = []\n",
    "        \n",
    "        # validation history storage\n",
    "        v_accur = []\n",
    "        v_loss = []\n",
    "\n",
    "        if x_train.shape[0] % batch_size == 0:\n",
    "            nb_train_steps = x_train.shape[0] // batch_size\n",
    "        else:\n",
    "            nb_train_steps = (x_train.shape[0] // batch_size) + 1\n",
    "        # Training Loop\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch ({epoch +1 }/{epochs})\")\n",
    "            for i in range(nb_train_steps):\n",
    "                # Batching data\n",
    "                x = x_train[i*batch_size:(i+1)*batch_size]\n",
    "                y = y_train[i*batch_size:(i+1)*batch_size]\n",
    "                \n",
    "                x = tf.constant(x)\n",
    "                y = tf.constant(y)\n",
    "                \n",
    "                with tf.GradientTape() as tape:\n",
    "                    # Forward pass\n",
    "                    predictions = self.model(x, training = True)\n",
    "                    # calcul de la loss\n",
    "                    loss = self.loss_fn(y, predictions)\n",
    "                    \n",
    "                # Calcul du gradient\n",
    "                grads = tape.gradient(loss, self.model.trainable_weights)\n",
    "                \n",
    "                # Decente de gradient\n",
    "                self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "                \n",
    "                #Pruning step\n",
    "                self.pruning(P_factor = self.pruning_factor)\n",
    "                \n",
    "                # Update training metric.\n",
    "                self.acc_metric.update_state(y, predictions)\n",
    "                train_acc = self.acc_metric.result()\n",
    "                \n",
    "                print(\"Accuracy: {:.4f} ; loss: {:.4f}\".format(float(train_acc),  loss), end='\\r')\n",
    "            print(\"\\nValidation Step :\")\n",
    "            \n",
    "            # Validation step\n",
    "            val_accur, val_loss = self.test(val_data, val_labels)\n",
    "                \n",
    "            accur.append(float(train_acc))\n",
    "            L.append(loss)\n",
    "            \n",
    "            v_accur.append(val_accur)\n",
    "            v_loss.append(val_loss)\n",
    "            print(\"\")\n",
    "        return (accur, L, v_accur, v_loss)  \n",
    "\n",
    "    \n",
    "    # Test Step \n",
    "    def test(self,data, labels):\n",
    "        accur = []\n",
    "        l = []\n",
    "        if data.shape[0] % self.batch_size == 0:\n",
    "            nb_test_steps = data.shape[0] // self.batch_size\n",
    "        else:\n",
    "            nb_test_steps = (data.shape[0] // self.batch_size) + 1\n",
    "            \n",
    "        for i in range(nb_test_steps):\n",
    "            # Batching data\n",
    "            x = data[i*self.batch_size:(i+1)*self.batch_size]\n",
    "            y = labels[i*self.batch_size:(i+1)*self.batch_size]\n",
    "            \n",
    "            x = tf.constant(x)\n",
    "            y = tf.constant(y)\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = self.model(x)\n",
    "\n",
    "            # calcul de la loss\n",
    "            loss = self.loss_fn(y, predictions)\n",
    "            # calcul de l'accuracy\n",
    "            self.acc_metric.update_state(y, predictions)\n",
    "            test_acc = self.acc_metric.result()\n",
    "            print(\"Accuracy: {:.4f} ; loss: {:.4f}\".format(float(test_acc),  loss), end='\\r')\n",
    "                \n",
    "            accur.append(float(test_acc))\n",
    "            l.append(float(loss))\n",
    "        print(\"\")        \n",
    "        print(\"Accuracy Moy : {:.4f} ; loss Moy: {:.4f}\" .format(np.mean(accur), np.mean(l) ))\n",
    "        \n",
    "        return (np.mean(accur), np.mean(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a5752f",
   "metadata": {},
   "source": [
    "## Training Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d5d9fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch (1/75)\n",
      "Accuracy: 0.9126 ; loss: 0.0162\n",
      "Validation Step :\n",
      "Accuracy: 0.9200 ; loss: 0.0030\n",
      "Accuracy Moy : 0.9161 ; loss Moy: 0.1114\n",
      "\n",
      "Epoch (2/75)\n",
      "Accuracy: 0.9455 ; loss: 0.0045\n",
      "Validation Step :\n",
      "Accuracy: 0.9478 ; loss: 0.0005\n",
      "Accuracy Moy : 0.9466 ; loss Moy: 0.0698\n",
      "\n",
      "Epoch (3/75)\n",
      "Accuracy: 0.9582 ; loss: 0.0026\n",
      "Validation Step :\n",
      "Accuracy: 0.9591 ; loss: 0.0010\n",
      "Accuracy Moy : 0.9585 ; loss Moy: 0.0661\n",
      "\n",
      "Epoch (4/75)\n",
      "Accuracy: 0.9651 ; loss: 0.0019\n",
      "Validation Step :\n",
      "Accuracy: 0.9656 ; loss: 0.0002\n",
      "Accuracy Moy : 0.9653 ; loss Moy: 0.0583\n",
      "\n",
      "Epoch (5/75)\n",
      "Accuracy: 0.9697 ; loss: 0.0010\n",
      "Validation Step :\n",
      "Accuracy: 0.9702 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9699 ; loss Moy: 0.0477\n",
      "\n",
      "Epoch (6/75)\n",
      "Accuracy: 0.9731 ; loss: 0.0006\n",
      "Validation Step :\n",
      "Accuracy: 0.9734 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9732 ; loss Moy: 0.0515\n",
      "\n",
      "Epoch (7/75)\n",
      "Accuracy: 0.9757 ; loss: 0.0004\n",
      "Validation Step :\n",
      "Accuracy: 0.9759 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9757 ; loss Moy: 0.0479\n",
      "\n",
      "Epoch (8/75)\n",
      "Accuracy: 0.9777 ; loss: 0.0003\n",
      "Validation Step :\n",
      "Accuracy: 0.9779 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9778 ; loss Moy: 0.0505\n",
      "\n",
      "Epoch (9/75)\n",
      "Accuracy: 0.9794 ; loss: 0.0015\n",
      "Validation Step :\n",
      "Accuracy: 0.9795 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9794 ; loss Moy: 0.0531\n",
      "\n",
      "Epoch (10/75)\n",
      "Accuracy: 0.9807 ; loss: 0.0014\n",
      "Validation Step :\n",
      "Accuracy: 0.9807 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9807 ; loss Moy: 0.0537\n",
      "\n",
      "Epoch (11/75)\n",
      "Accuracy: 0.9818 ; loss: 0.0002\n",
      "Validation Step :\n",
      "Accuracy: 0.9818 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9818 ; loss Moy: 0.0528\n",
      "\n",
      "Epoch (12/75)\n",
      "Accuracy: 0.9828 ; loss: 0.0006\n",
      "Validation Step :\n",
      "Accuracy: 0.9828 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9828 ; loss Moy: 0.0667\n",
      "\n",
      "Epoch (13/75)\n",
      "Accuracy: 0.9837 ; loss: 0.0009\n",
      "Validation Step :\n",
      "Accuracy: 0.9836 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9836 ; loss Moy: 0.0808\n",
      "\n",
      "Epoch (14/75)\n",
      "Accuracy: 0.9844 ; loss: 0.0001\n",
      "Validation Step :\n",
      "Accuracy: 0.9844 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9844 ; loss Moy: 0.0492\n",
      "\n",
      "Epoch (15/75)\n",
      "Accuracy: 0.9850 ; loss: 0.0002\n",
      "Validation Step :\n",
      "Accuracy: 0.9851 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9850 ; loss Moy: 0.0579\n",
      "\n",
      "Epoch (16/75)\n",
      "Accuracy: 0.9857 ; loss: 0.0001\n",
      "Validation Step :\n",
      "Accuracy: 0.9857 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9857 ; loss Moy: 0.0506\n",
      "\n",
      "Epoch (17/75)\n",
      "Accuracy: 0.9862 ; loss: 0.0001\n",
      "Validation Step :\n",
      "Accuracy: 0.9862 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9862 ; loss Moy: 0.0614\n",
      "\n",
      "Epoch (18/75)\n",
      "Accuracy: 0.9867 ; loss: 0.0017\n",
      "Validation Step :\n",
      "Accuracy: 0.9867 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9867 ; loss Moy: 0.0529\n",
      "\n",
      "Epoch (19/75)\n",
      "Accuracy: 0.9872 ; loss: 0.0009\n",
      "Validation Step :\n",
      "Accuracy: 0.9872 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9872 ; loss Moy: 0.0598\n",
      "\n",
      "Epoch (20/75)\n",
      "Accuracy: 0.9877 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9877 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9877 ; loss Moy: 0.0588\n",
      "\n",
      "Epoch (21/75)\n",
      "Accuracy: 0.9881 ; loss: 0.0028\n",
      "Validation Step :\n",
      "Accuracy: 0.9881 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9881 ; loss Moy: 0.0698\n",
      "\n",
      "Epoch (22/75)\n",
      "Accuracy: 0.9884 ; loss: 0.0002\n",
      "Validation Step :\n",
      "Accuracy: 0.9884 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9884 ; loss Moy: 0.0742\n",
      "\n",
      "Epoch (23/75)\n",
      "Accuracy: 0.9888 ; loss: 0.0003\n",
      "Validation Step :\n",
      "Accuracy: 0.9888 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9888 ; loss Moy: 0.0672\n",
      "\n",
      "Epoch (24/75)\n",
      "Accuracy: 0.9891 ; loss: 0.0001\n",
      "Validation Step :\n",
      "Accuracy: 0.9891 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9891 ; loss Moy: 0.0669\n",
      "\n",
      "Epoch (25/75)\n",
      "Accuracy: 0.9894 ; loss: 0.0030\n",
      "Validation Step :\n",
      "Accuracy: 0.9894 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9894 ; loss Moy: 0.0699\n",
      "\n",
      "Epoch (26/75)\n",
      "Accuracy: 0.9896 ; loss: 0.0001\n",
      "Validation Step :\n",
      "Accuracy: 0.9896 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9896 ; loss Moy: 0.0589\n",
      "\n",
      "Epoch (27/75)\n",
      "Accuracy: 0.9899 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9899 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9899 ; loss Moy: 0.0629\n",
      "\n",
      "Epoch (28/75)\n",
      "Accuracy: 0.9902 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9901 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9901 ; loss Moy: 0.0727\n",
      "\n",
      "Epoch (29/75)\n",
      "Accuracy: 0.9904 ; loss: 0.0004\n",
      "Validation Step :\n",
      "Accuracy: 0.9904 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9904 ; loss Moy: 0.0643\n",
      "\n",
      "Epoch (30/75)\n",
      "Accuracy: 0.9906 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9906 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9906 ; loss Moy: 0.0669\n",
      "\n",
      "Epoch (31/75)\n",
      "Accuracy: 0.9908 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9908 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9908 ; loss Moy: 0.0903\n",
      "\n",
      "Epoch (32/75)\n",
      "Accuracy: 0.9910 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9909 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9909 ; loss Moy: 0.0696\n",
      "\n",
      "Epoch (33/75)\n",
      "Accuracy: 0.9911 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9911 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9911 ; loss Moy: 0.0610\n",
      "\n",
      "Epoch (34/75)\n",
      "Accuracy: 0.9913 ; loss: 0.0001\n",
      "Validation Step :\n",
      "Accuracy: 0.9913 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9913 ; loss Moy: 0.0680\n",
      "\n",
      "Epoch (35/75)\n",
      "Accuracy: 0.9915 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9915 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9915 ; loss Moy: 0.0748\n",
      "\n",
      "Epoch (36/75)\n",
      "Accuracy: 0.9917 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9917 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9917 ; loss Moy: 0.0628\n",
      "\n",
      "Epoch (37/75)\n",
      "Accuracy: 0.9918 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9918 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9918 ; loss Moy: 0.0607\n",
      "\n",
      "Epoch (38/75)\n",
      "Accuracy: 0.9920 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9920 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9920 ; loss Moy: 0.0629\n",
      "\n",
      "Epoch (39/75)\n",
      "Accuracy: 0.9921 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9921 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9921 ; loss Moy: 0.0592\n",
      "\n",
      "Epoch (40/75)\n",
      "Accuracy: 0.9922 ; loss: 0.0002\n",
      "Validation Step :\n",
      "Accuracy: 0.9922 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9922 ; loss Moy: 0.0631\n",
      "\n",
      "Epoch (41/75)\n",
      "Accuracy: 0.9924 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9924 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9924 ; loss Moy: 0.0668\n",
      "\n",
      "Epoch (42/75)\n",
      "Accuracy: 0.9925 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9925 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9925 ; loss Moy: 0.0595\n",
      "\n",
      "Epoch (43/75)\n",
      "Accuracy: 0.9926 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9926 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9926 ; loss Moy: 0.0576\n",
      "\n",
      "Epoch (44/75)\n",
      "Accuracy: 0.9928 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9927 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9928 ; loss Moy: 0.0718\n",
      "\n",
      "Epoch (45/75)\n",
      "Accuracy: 0.9929 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9929 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9929 ; loss Moy: 0.0608\n",
      "\n",
      "Epoch (46/75)\n",
      "Accuracy: 0.9930 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9930 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9930 ; loss Moy: 0.0565\n",
      "\n",
      "Epoch (47/75)\n",
      "Accuracy: 0.9931 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9931 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9931 ; loss Moy: 0.0573\n",
      "\n",
      "Epoch (48/75)\n",
      "Accuracy: 0.9932 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9932 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9932 ; loss Moy: 0.0598\n",
      "\n",
      "Epoch (49/75)\n",
      "Accuracy: 0.9933 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9933 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9933 ; loss Moy: 0.0734\n",
      "\n",
      "Epoch (50/75)\n",
      "Accuracy: 0.9934 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9934 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9934 ; loss Moy: 0.0635\n",
      "\n",
      "Epoch (51/75)\n",
      "Accuracy: 0.9935 ; loss: 0.0001\n",
      "Validation Step :\n",
      "Accuracy: 0.9935 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9935 ; loss Moy: 0.0741\n",
      "\n",
      "Epoch (52/75)\n",
      "Accuracy: 0.9936 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9936 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9936 ; loss Moy: 0.0633\n",
      "\n",
      "Epoch (53/75)\n",
      "Accuracy: 0.9937 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9937 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9937 ; loss Moy: 0.0660\n",
      "\n",
      "Epoch (54/75)\n",
      "Accuracy: 0.9938 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9938 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9938 ; loss Moy: 0.0667\n",
      "\n",
      "Epoch (55/75)\n",
      "Accuracy: 0.9939 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9939 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9939 ; loss Moy: 0.0673\n",
      "\n",
      "Epoch (56/75)\n",
      "Accuracy: 0.9940 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9939 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9939 ; loss Moy: 0.0678\n",
      "\n",
      "Epoch (57/75)\n",
      "Accuracy: 0.9940 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9940 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9940 ; loss Moy: 0.0683\n",
      "\n",
      "Epoch (58/75)\n",
      "Accuracy: 0.9941 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9941 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9941 ; loss Moy: 0.0687\n",
      "\n",
      "Epoch (59/75)\n",
      "Accuracy: 0.9942 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9942 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9942 ; loss Moy: 0.0691\n",
      "\n",
      "Epoch (60/75)\n",
      "Accuracy: 0.9943 ; loss: 0.0000\n",
      "Validation Step :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9942 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9942 ; loss Moy: 0.0695\n",
      "\n",
      "Epoch (61/75)\n",
      "Accuracy: 0.9943 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9943 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9943 ; loss Moy: 0.0698\n",
      "\n",
      "Epoch (62/75)\n",
      "Accuracy: 0.9944 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9944 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9944 ; loss Moy: 0.0702\n",
      "\n",
      "Epoch (63/75)\n",
      "Accuracy: 0.9945 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9945 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9945 ; loss Moy: 0.0705\n",
      "\n",
      "Epoch (64/75)\n",
      "Accuracy: 0.9945 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9945 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9945 ; loss Moy: 0.0708\n",
      "\n",
      "Epoch (65/75)\n",
      "Accuracy: 0.9946 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9946 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9946 ; loss Moy: 0.0710\n",
      "\n",
      "Epoch (66/75)\n",
      "Accuracy: 0.9946 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9946 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9946 ; loss Moy: 0.0713\n",
      "\n",
      "Epoch (67/75)\n",
      "Accuracy: 0.9947 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9947 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9947 ; loss Moy: 0.0716\n",
      "\n",
      "Epoch (68/75)\n",
      "Accuracy: 0.9948 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9948 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9948 ; loss Moy: 0.0718\n",
      "\n",
      "Epoch (69/75)\n",
      "Accuracy: 0.9948 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9948 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9948 ; loss Moy: 0.0720\n",
      "\n",
      "Epoch (70/75)\n",
      "Accuracy: 0.9949 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9949 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9949 ; loss Moy: 0.0723\n",
      "\n",
      "Epoch (71/75)\n",
      "Accuracy: 0.9949 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9949 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9949 ; loss Moy: 0.0725\n",
      "\n",
      "Epoch (72/75)\n",
      "Accuracy: 0.9950 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9950 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9950 ; loss Moy: 0.0727\n",
      "\n",
      "Epoch (73/75)\n",
      "Accuracy: 0.9950 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9950 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9950 ; loss Moy: 0.0729\n",
      "\n",
      "Epoch (74/75)\n",
      "Accuracy: 0.9951 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9951 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9951 ; loss Moy: 0.0731\n",
      "\n",
      "Epoch (75/75)\n",
      "Accuracy: 0.9951 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9951 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9951 ; loss Moy: 0.0733\n",
      "\n",
      "Epoch (1/15)\n",
      "Accuracy: 1.0000 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9991 ; loss Moy: 0.0733\n",
      "\n",
      "Epoch (2/15)\n",
      "Accuracy: 0.9992 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9988 ; loss Moy: 0.0733\n",
      "\n",
      "Epoch (3/15)\n",
      "Accuracy: 0.9990 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9987 ; loss Moy: 0.0733\n",
      "\n",
      "Epoch (4/15)\n",
      "Accuracy: 0.9989 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9987 ; loss Moy: 0.0733\n",
      "\n",
      "Epoch (5/15)\n",
      "Accuracy: 0.9988 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9987 ; loss Moy: 0.0734\n",
      "\n",
      "Epoch (6/15)\n",
      "Accuracy: 0.9988 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9987 ; loss Moy: 0.0734\n",
      "\n",
      "Epoch (7/15)\n",
      "Accuracy: 0.9988 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9987 ; loss Moy: 0.0734\n",
      "\n",
      "Epoch (8/15)\n",
      "Accuracy: 0.9987 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9986 ; loss Moy: 0.0734\n",
      "\n",
      "Epoch (9/15)\n",
      "Accuracy: 0.9987 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9986 ; loss Moy: 0.0734\n",
      "\n",
      "Epoch (10/15)\n",
      "Accuracy: 0.9987 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9986 ; loss Moy: 0.0735\n",
      "\n",
      "Epoch (11/15)\n",
      "Accuracy: 0.9987 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9986 ; loss Moy: 0.0735\n",
      "\n",
      "Epoch (12/15)\n",
      "Accuracy: 0.9987 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9986 ; loss Moy: 0.0735\n",
      "\n",
      "Epoch (13/15)\n",
      "Accuracy: 0.9987 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9986 ; loss Moy: 0.0735\n",
      "\n",
      "Epoch (14/15)\n",
      "Accuracy: 0.9987 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9986 ; loss Moy: 0.0735\n",
      "\n",
      "Epoch (15/15)\n",
      "Accuracy: 0.9987 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9986 ; loss Moy: 0.0735\n",
      "\n",
      "Epoch (1/10)\n",
      "Accuracy: 1.0000 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9991 ; loss Moy: 0.0735\n",
      "\n",
      "Epoch (2/10)\n",
      "Accuracy: 0.9992 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9988 ; loss Moy: 0.0735\n",
      "\n",
      "Epoch (3/10)\n",
      "Accuracy: 0.9990 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9987 ; loss Moy: 0.0735\n",
      "\n",
      "Epoch (4/10)\n",
      "Accuracy: 0.9989 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9987 ; loss Moy: 0.0735\n",
      "\n",
      "Epoch (5/10)\n",
      "Accuracy: 0.9988 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9987 ; loss Moy: 0.0735\n",
      "\n",
      "Epoch (6/10)\n",
      "Accuracy: 0.9988 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9987 ; loss Moy: 0.0735\n",
      "\n",
      "Epoch (7/10)\n",
      "Accuracy: 0.9988 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9987 ; loss Moy: 0.0735\n",
      "\n",
      "Epoch (8/10)\n",
      "Accuracy: 0.9987 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9986 ; loss Moy: 0.0735\n",
      "\n",
      "Epoch (9/10)\n",
      "Accuracy: 0.9987 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9986 ; loss Moy: 0.0736\n",
      "\n",
      "Epoch (10/10)\n",
      "Accuracy: 0.9987 ; loss: 0.0000\n",
      "Validation Step :\n",
      "Accuracy: 0.9986 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9986 ; loss Moy: 0.0736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-20 12:33:06.854445: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n",
      "2022-07-20 12:33:07.111086: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scratch inference time :  0.5574287176132202  s\n",
      "Pruned inference time :  0.5616897821426392  s\n",
      "Epoch (1/75)\n",
      "Accuracy: 0.9196 ; loss: 0.0219\n",
      "Validation Step :\n",
      "Accuracy: 0.9266 ; loss: 0.0024\n",
      "Accuracy Moy : 0.9229 ; loss Moy: 0.0979\n",
      "\n",
      "Epoch (2/75)\n",
      "Accuracy: 0.9490 ; loss: 0.0247\n",
      "Validation Step :\n",
      "Accuracy: 0.9510 ; loss: 0.0004\n",
      "Accuracy Moy : 0.9498 ; loss Moy: 0.0698\n",
      "\n",
      "Epoch (3/75)\n",
      "Accuracy: 0.9601 ; loss: 0.0040\n",
      "Validation Step :\n",
      "Accuracy: 0.9609 ; loss: 0.0002\n",
      "Accuracy Moy : 0.9604 ; loss Moy: 0.0658\n",
      "\n",
      "Epoch (4/75)\n",
      "Accuracy: 0.9662 ; loss: 0.0017\n",
      "Validation Step :\n",
      "Accuracy: 0.9668 ; loss: 0.0001\n",
      "Accuracy Moy : 0.9664 ; loss Moy: 0.0564\n",
      "\n",
      "Epoch (5/75)\n",
      "Accuracy: 0.9704 ; loss: 0.0016\n",
      "Validation Step :\n",
      "Accuracy: 0.9708 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9706 ; loss Moy: 0.0509\n",
      "\n",
      "Epoch (6/75)\n",
      "Accuracy: 0.9735 ; loss: 0.0013\n",
      "Validation Step :\n",
      "Accuracy: 0.9738 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9736 ; loss Moy: 0.0484\n",
      "\n",
      "Epoch (7/75)\n",
      "Accuracy: 0.9759 ; loss: 0.0015\n",
      "Validation Step :\n",
      "Accuracy: 0.9761 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9760 ; loss Moy: 0.0449\n",
      "\n",
      "Epoch (8/75)\n",
      "Accuracy: 0.9778 ; loss: 0.0018\n",
      "Validation Step :\n",
      "Accuracy: 0.9780 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9779 ; loss Moy: 0.0466\n",
      "\n",
      "Epoch (9/75)\n",
      "Accuracy: 0.9794 ; loss: 0.0014\n",
      "Validation Step :\n",
      "Accuracy: 0.9795 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9794 ; loss Moy: 0.0515\n",
      "\n",
      "Epoch (10/75)\n",
      "Accuracy: 0.9807 ; loss: 0.0318\n",
      "Validation Step :\n",
      "Accuracy: 0.9808 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9807 ; loss Moy: 0.0510\n",
      "\n",
      "Epoch (11/75)\n",
      "Accuracy: 0.9819 ; loss: 0.0006\n",
      "Validation Step :\n",
      "Accuracy: 0.9819 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9819 ; loss Moy: 0.0491\n",
      "\n",
      "Epoch (12/75)\n",
      "Accuracy: 0.9829 ; loss: 0.0005\n",
      "Validation Step :\n",
      "Accuracy: 0.9829 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9829 ; loss Moy: 0.0494\n",
      "\n",
      "Epoch (13/75)\n",
      "Accuracy: 0.9837 ; loss: 0.0006\n",
      "Validation Step :\n",
      "Accuracy: 0.9837 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9837 ; loss Moy: 0.0512\n",
      "\n",
      "Epoch (14/75)\n",
      "Accuracy: 0.9844 ; loss: 0.0023\n",
      "Validation Step :\n",
      "Accuracy: 0.9845 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9844 ; loss Moy: 0.0497\n",
      "\n",
      "Epoch (15/75)\n",
      "Accuracy: 0.9851 ; loss: 0.0050\n",
      "Validation Step :\n",
      "Accuracy: 0.9851 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9851 ; loss Moy: 0.0549\n",
      "\n",
      "Epoch (16/75)\n",
      "Accuracy: 0.9857 ; loss: 0.0042\n",
      "Validation Step :\n",
      "Accuracy: 0.9857 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9857 ; loss Moy: 0.0509\n",
      "\n",
      "Epoch (17/75)\n",
      "Accuracy: 0.9862 ; loss: 0.0006\n",
      "Validation Step :\n",
      "Accuracy: 0.9862 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9862 ; loss Moy: 0.0542\n",
      "\n",
      "Epoch (18/75)\n",
      "Accuracy: 0.9867 ; loss: 0.0004\n",
      "Validation Step :\n",
      "Accuracy: 0.9867 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9867 ; loss Moy: 0.0498\n",
      "\n",
      "Epoch (19/75)\n",
      "Accuracy: 0.9872 ; loss: 0.0001\n",
      "Validation Step :\n",
      "Accuracy: 0.9872 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9872 ; loss Moy: 0.0603\n",
      "\n",
      "Epoch (20/75)\n",
      "Accuracy: 0.9876 ; loss: 0.0004\n",
      "Validation Step :\n",
      "Accuracy: 0.9876 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9876 ; loss Moy: 0.0638\n",
      "\n",
      "Epoch (21/75)\n",
      "Accuracy: 0.9880 ; loss: 0.0034\n",
      "Validation Step :\n",
      "Accuracy: 0.9879 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9879 ; loss Moy: 0.0670\n",
      "\n",
      "Epoch (22/75)\n",
      "Accuracy: 0.9883 ; loss: 0.0005\n",
      "Validation Step :\n",
      "Accuracy: 0.9883 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9883 ; loss Moy: 0.0627\n",
      "\n",
      "Epoch (23/75)\n",
      "Accuracy: 0.9886 ; loss: 0.0001\n",
      "Validation Step :\n",
      "Accuracy: 0.9886 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9886 ; loss Moy: 0.0623\n",
      "\n",
      "Epoch (24/75)\n",
      "Accuracy: 0.9889 ; loss: 0.0001\n",
      "Validation Step :\n",
      "Accuracy: 0.9889 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9889 ; loss Moy: 0.0582\n",
      "\n",
      "Epoch (25/75)\n",
      "Accuracy: 0.9891 ; loss: 0.0030\n",
      "Validation Step :\n",
      "Accuracy: 0.9891 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9891 ; loss Moy: 0.0708\n",
      "\n",
      "Epoch (26/75)\n",
      "Accuracy: 0.9894 ; loss: 0.0031\n",
      "Validation Step :\n",
      "Accuracy: 0.9894 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9894 ; loss Moy: 0.0656\n",
      "\n",
      "Epoch (27/75)\n",
      "Accuracy: 0.9897 ; loss: 0.0161\n",
      "Validation Step :\n",
      "Accuracy: 0.9896 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9896 ; loss Moy: 0.0629\n",
      "\n",
      "Epoch (28/75)\n",
      "Accuracy: 0.9899 ; loss: 0.0008\n",
      "Validation Step :\n",
      "Accuracy: 0.9899 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9899 ; loss Moy: 0.0675\n",
      "\n",
      "Epoch (29/75)\n",
      "Accuracy: 0.9901 ; loss: 0.0001\n",
      "Validation Step :\n",
      "Accuracy: 0.9901 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9901 ; loss Moy: 0.0681\n",
      "\n",
      "Epoch (30/75)\n",
      "Accuracy: 0.9903 ; loss: 0.0004\n",
      "Validation Step :\n",
      "Accuracy: 0.9903 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9903 ; loss Moy: 0.0711\n",
      "\n",
      "Epoch (31/75)\n",
      "Accuracy: 0.9905 ; loss: 0.0001\n",
      "Validation Step :\n",
      "Accuracy: 0.9905 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9905 ; loss Moy: 0.0685\n",
      "\n",
      "Epoch (32/75)\n",
      "Accuracy: 0.9907 ; loss: 0.0111\n",
      "Validation Step :\n",
      "Accuracy: 0.9907 ; loss: 0.0000\n",
      "Accuracy Moy : 0.9907 ; loss Moy: 0.0685\n",
      "\n",
      "Epoch (33/75)\n",
      "Accuracy: 0.9908 ; loss: 0.0001\r"
     ]
    }
   ],
   "source": [
    "for p in [0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    accuracy = np.array([])\n",
    "    val_accuracy = np.array([])\n",
    "\n",
    "    l = np.array([])\n",
    "    val_l = np.array([])\n",
    "\n",
    "\n",
    "    P = Pruning(tf.keras.models.clone_model(model), \n",
    "                pruning_factor =p)\n",
    "    lr = 1\n",
    "    for epoch in [75,15,10]:\n",
    "        # Param√®tre d'entrainement\n",
    "        lr /= 10\n",
    "        P.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=lr),\n",
    "                 loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                 metric = tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "        )\n",
    "\n",
    "        # Entrainement         \n",
    "        accur, loss, val_accur, val_loss = P.train(x_train, y_train, \n",
    "                                                   x_test, y_test, \n",
    "                                                   epochs = epoch, \n",
    "                                                   batch_size= 32 )  \n",
    "\n",
    "\n",
    "        # plot hist\n",
    "        accuracy = np.append(accuracy, accur)\n",
    "        val_accuracy = np.append(val_accuracy, val_accur)\n",
    "        l = np.append(l, loss)\n",
    "        val_l = np.append(val_l,val_loss)\n",
    "    \n",
    "    # Afficher les courbes d'entrainement\n",
    "    #plot_hist(f\"Lenet5_P_factor_{p}.png\")\n",
    "    \n",
    "    # inference time\n",
    "    pruned_inf_time = inference_time()\n",
    "    \n",
    "    # Enregister l'historique\n",
    "    dico[f\"P_factor_{p}_hist\"] = (accuracy, val_accuracy, l, val_l)\n",
    "    \n",
    "    # calcul du temps d'inf√©rence\n",
    "    dico[f\"P_factor_{p}_inf_time\"] = pruned_inf_time\n",
    "\n",
    "    \n",
    "    # memory used\n",
    "    dico[f\"nb_params_p_factor_{p}\"] = count_parameters(P.model)\n",
    "    \n",
    "    # sauvegarder les poids\n",
    "    P.model.save_weights(f\"w_Lenet5_p_{p}.h5\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c317b",
   "metadata": {},
   "source": [
    "## Evaluation des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9839b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_plot(dic, figname, scratch = False):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    for p in [0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "        # Train accuracy\n",
    "        plt.subplot(221)\n",
    "        plt.plot(dic[f\"P_factor_{p}_hist\"][0], label = f\"{p}\")\n",
    "\n",
    "        plt.title(\"Train accuracy\")\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "\n",
    "        # Validation accuracy\n",
    "        plt.subplot(222)\n",
    "        plt.plot(dico[f\"P_factor_{p}_hist\"][1], label = f\"{p}\")\n",
    "\n",
    "        plt.title(\"Validation accuracy\")\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "\n",
    "        # train loss\n",
    "        plt.subplot(223)\n",
    "        plt.plot(dic[f\"P_factor_{p}_hist\"][2], label = f\"{p}\")\n",
    "\n",
    "        plt.title(\"Train loss\")\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "\n",
    "        # validation loss\n",
    "        plt.subplot(224)\n",
    "        plt.plot(dic[f\"P_factor_{p}_hist\"][3], label = f\"{p}\")\n",
    "\n",
    "        plt.title(\"Validation loss\")\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        \n",
    "    if scratch == True: \n",
    "        # Courbe scratch\n",
    "        plt.subplot(221)\n",
    "        plt.plot(dic[\"scratch_hist\"][0], label = \"Scratch Train accur\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy Value\")\n",
    "\n",
    "        plt.subplot(222)\n",
    "        plt.plot(dic[\"scratch_hist\"][1], label = \"Scratch Val accur\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy Value\")\n",
    "\n",
    "        plt.subplot(223)\n",
    "        plt.plot(dic[\"scratch_hist\"][2], label = \"Scratch Train loss\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss Value\")\n",
    "\n",
    "\n",
    "        plt.subplot(224)\n",
    "        plt.plot(dic[\"scratch_hist\"][3], label = \"Scratch Val loss\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss Value\")\n",
    "    \n",
    "    \n",
    "    plt.savefig(figname)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df765246",
   "metadata": {},
   "outputs": [],
   "source": [
    "figname= f\"test2_seed42.png\"\n",
    "eval_plot(dico, figname, scratch = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cde3c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "135d21e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data\n",
    "np.save(\"summary_Lenet_mnist_padded.npy\", dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a10f704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
